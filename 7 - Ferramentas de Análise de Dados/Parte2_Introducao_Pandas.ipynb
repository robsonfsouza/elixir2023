{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introdução à biblioteca Pandas\n",
    "\n",
    "O objetivo dessa parte da aula é ensinar como carregar e manipular dados com Pandas.\n",
    "\n",
    "Uma vez que os conceitos básicos dessa biblioteca são dominados, é possível fazer manipulações complexas de grandes volumes de dados com esforço mínimo de programação.\n",
    "\n",
    "## Tópicos\n",
    "\n",
    "1. [Introdução](#introducao)\n",
    "    1. [Carregando a biblioteca Pandas](#carregando)\n",
    "    2. [Criando um DataFrame](#criando)\n",
    "    3. [Acessando dados em colunas](#coluna)\n",
    "    4. [Acessando dados em uma linha](#linha)\n",
    "    5. [Acessando dados em uma célula](#celula)\n",
    "    6. [Carregando tabelas de arquivos](#arquivos)\n",
    "    7. [Calculando estatísticas](#estatisticas)\n",
    "        1. [Pandas Series](#series)\n",
    "    8. [Limpando dados](#limpando)\n",
    "    9. [Cruzando dados de tabelas diferentes](#merge)\n",
    "    10. [Agrupando linhas](#agrupando)\n",
    "    11. [Visualização gráfica](#visualizacao)\n",
    "2. [Exemplos com dados biológicos](#exemplo1)\n",
    "    1. [Qual a proteína?](#proteina)\n",
    "    2. [Reunindo dados de várias tabelas](#exemplo_cruzando)\n",
    "    3. [Tabelas grandes](#exemplo_grandes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"introducao\"></a>\n",
    "## Introdução\n",
    "\n",
    "A [biblioteca Pandas](https://pandas.pydata.org/) é uma biblioteca da linguagem Python que implementa um grande conjunto de ferramentas para análise descritiva dos dados, incluindo funções para cálculo de estatísticas, visualização de dados e outras análises, nas quais se destaca por seu alto desempenho.\n",
    "\n",
    "Com a integração com outras bibliotecas, como [NumPy](https://numpy.org/), na qual Pandas é baseada, e [Matplotlib](https://matplotlib.org/), o usuário pode fazer uma análise completa de seus dados.\n",
    "\n",
    "<a id=\"carregando\"></a>\n",
    "### 1.A. Carregando a biblioteca Pandas\n",
    "\n",
    "O primeiro passo para usar Pandas é carregar a biblioteca no seu ambiente de execução Python.\n",
    "\n",
    "Seguindo a convenção da comunidade, importamos a biblioteca em nosso ambiente com o nome `pd`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"criando\"></a>\n",
    "## 1.B. Criando um DataFrame\n",
    "\n",
    "O DataFrame é o objeto mais importante na biblioteca Pandas e, conceitualmente, é similar a uma folha ou aba de uma [planilha eletrônica](https://docs.google.com/spreadsheets/d/1kODe8LtSMOsxx98zYsnt0QIPgeTAlZC3lV0z5lCZtq0/edit#gid=0).\n",
    "\n",
    "Como uma planilha, o DataFrame armazena tabelas e tem linhas e colunas identificadas por nomes ou números.\n",
    "\n",
    "O exemplo abaixo cria e imprime um DataFrame simples, com dados numéricos, colunas `a` e `b` e identificadores de linhas 0 e 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame([['r3',100,200],['r1',1,10],['r2',30,67]], columns=['a','b','c'], index=['n1','n2','n3'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note como a lista de listas original\n",
    "\n",
    "`[['r3',100,200],['r1',1,10],['r2',30,67]]`\n",
    "\n",
    "onde cada elemento é uma coluna, é convertida em uma tabela com o mesmo número de linhas e colunas.\n",
    "\n",
    "Nesse exemplo:\n",
    "\n",
    "* Os nomes das colunas foram especificados usando o parâmetro `columns`\n",
    "* Os nomes as linhas são definidos pelo parâmetro `index`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">__Nota__:\n",
    ">\n",
    ">Quando um Pandas DataFrame é criado sem especificar o índice, um índice será automaticamente criado e consistirá nos valores de zero ao número de linhas no DataFrame.\n",
    "\n",
    "__Checando dados no DataFrame__\n",
    "\n",
    "Uma vez criado o DataFrame, é sempre útil checar se ele tem a estrutura esperada em termos de\n",
    "\n",
    "* Colunas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Linhas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Número de linhas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Primeiras linhas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Últimas linhas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"coluna\"></a>\n",
    "## 1.C. Acessando dados em colunas\n",
    "\n",
    "Boa parte do sucesso do Pandas se deve à eficiência e simplicidade para manipular os dados nas colunas de um DataFrame.\n",
    "\n",
    "O modelo focado em colunas é reminescente do comportamento da linguagem [R](https://www.r-project.org/), que também otimiza as operações vetorizadas, ou seja, sobre listas.\n",
    "\n",
    "O acesso aos valores da coluna pode ser feito com a sintaxe de atributo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outra forma de acessar uma coluna é semelhante à usada para listas e dicionários:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['b']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "esta última forma permite adicionar novas colunas ao DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['d'] = 8\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O uso da sintaxe de atributo (`df.b`) ou de __um__ par de colchetes (`df['b']`) sempre retorna uma série ([`pandas.Series`](#series)).\n",
    "\n",
    "Outra alternativa é usar dois pares de colchetes (`df[['b']]`) para obter um Pandas Dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['b']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"linha\"></a>\n",
    "## 1.D. Acessando dados em uma linha\n",
    "\n",
    "Para acessar uma linha podemos usar o atributo `.loc` e o índice:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame([['r3',100,200],['r1',1,10],['r2',30,67]], columns=['a','b','c'], index=['n1','n2','n3'])\n",
    "df.loc['n2']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ou o número da linha e o atributo `iloc()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame([['r3',100,200],['r1',1,10],['r2',30,67]], columns=['a','b','c'], index=['n1','n2','n3'])\n",
    "df.iloc[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usando `iloc` e `.loc`, o resultado é uma série.\n",
    "\n",
    "Um recurso poderoso é usar uma lista ou série de valores booleanos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame([['r3',100,200],['r1',1,10],['r2',30,67]], columns=['a','b','c'], index=['n1','n2','n3'])\n",
    "df[[False,True,False]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A possibilidade de usar séries de valores booleanos gerados por uma busca é particularmente útil para permitir o rápido acesso a linhas de interesse, mesmo se o DataFrame for muito grande (*e.g.* dezenas de milhões de linhas)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.a == 'r1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nesse último caso, fizemos uso da flexibilidade das séries Pandas, que podem aplicar a comparação com uma variável escalar a todo os elementos da séries `df.a`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.a == 'r1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esse recurso da comparação com escalares ou com outras séries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.b < df.c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "é fundamental para o uso eficiente do Pandas, como veremos a seguir."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"celula\"></a>\n",
    "## 1.E. Acessando dados em uma célula\n",
    "\n",
    "Os DataFrames são arranjos bidimensionais e o acesso às células pode ser feito diretamente com as funções `iloc` e `loc`, que foram introduzidas na seção anterior, no contexto de extrair linhas do DataFrame como Séries.\n",
    "\n",
    "No exemplo abaixo, acessamos o valor na linha `n1` e coluna `c`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc['n1','c']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos também acessar o mesmo valor usando a posição da coluna e da linha:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[0,2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`iloc` e `loc` também permitem mudar os valores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc['n1','c'] = 300\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"arquivos\"></a>\n",
    "## 1.F. Trabalhando com tabelas de arquivos\n",
    "\n",
    "Na maioria dos casos os dados que nos interessam são obtidos em formatos como Excel, CSV, TSV e outros.\n",
    "\n",
    "Para carregar e salvar tabelas, vamos usar os métodos de entrada e saída do Pandas.\n",
    "\n",
    "O comando abaixo carrega a tabela `t2` de um arquivo ([t2.tsv](/edit/t2.tsv)) no formato TSV (*Tab Separated Values*), ou seja, um arquivo de texto com colunas separados por tabulações."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t2 = pd.read_csv(\"t2.tsv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">O exemplo acima poderia igualmente ter usado uma tabela Excel ou Google Sheets ou um arquivo muito mais contendo toneladas de dados. Para ver o repertório completo de formatos de arquivos suportados pelo Pandas veja a [documentação das ferramentas de IO](https://pandas.pydata.org/docs/user_guide/io.html). \n",
    "\n",
    "Vamos mudar um valor na tabela e salvá-la em um novo arquivo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t2.loc[2,'d'] = 15\n",
    "t2.to_csv(\"t3.tsv\", index=False)\n",
    "!cat \"t3.tsv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veja o arquivo salvo [nesse link](/edit/t3.tsv) e note que o separador de colunas usado foi a vírgula (\",\") ao invés da tabulação usada na entrada. O valor mudado está na quarta linha do arquivo, coluna `d`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"estatisticas\"></a>\n",
    "## 1.G Calculando estatísticas\n",
    "\n",
    "Em Pandas podemos calcular estatísticas sobre toda a tabela ou sobre colunas individuais.\n",
    "\n",
    "Para trabalharmos eficientemente com colunas, precisamos conhecer a classe Series do Pandas.\n",
    "\n",
    "<a id=\"series\"></a>\n",
    "### 1.G.a Pandas Series\n",
    "\n",
    "Ao acessar uma coluna de um DataFrame usando a sintaxe de atributo, podemos notar que a coluna não é uma lista padrão do Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df.b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na verdade a coluna é um objeto da classe [`pandas.Series`](https://pandas.pydata.org/docs/user_guide/dsintro.html#series), que consiste em um arranjo unidimensional capaz de:\n",
    "\n",
    "1. Armazenar qualquer tipo de dado\n",
    "2. Dar nomes aos elementos no arranjo\n",
    "\n",
    "Um Pandas DataFrame (tabela) pode ser entendido como um conjunto de Pandas Series (colunas).\n",
    "\n",
    "Uma *Pandas Series* pode ser criada passando os dados e suas etiquetas (nomes) para o construtor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series([0,1,2,3], index=['a','b','c','d'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os métodos da classe `pandas.Series` servem de base para métodos equivalentes em DataFrames.\n",
    "\n",
    "__Exemplos de métodos que calculam estatísticas:__\n",
    "\n",
    "* Identificar o valor máximo de uma série"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = pd.read_csv(\"t1.tsv\", sep=\"\\t\")\n",
    "t1.b.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Calcular a média"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1.c.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Desvio padrão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1.b.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Outras funções úteis para trabalhar com séries__\n",
    "\n",
    "* Colocar os valor da série em ordem (decrescente, nesse caso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = pd.Series([0,1,2,3], index=['a','b','c','d'])\n",
    "b.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embora as duas operações acima também estejam disponíveis em listas, as séries trazem muitas outras vantagens.\n",
    "\n",
    "Além da grande velocidade das operações serializadas, as séries ainda disponibilizam\n",
    "\n",
    "1. Vários métodos que não as listas não suportam, tais como\n",
    "2. Transformações simplificadas com operadores e ourtas classes\n",
    "\n",
    "Alguns exemplos de métodos e operações exclusivos de séries:\n",
    "\n",
    "* Amostrar elementos na série"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = pd.Series(list(range(1000)))\n",
    "b.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">O exemplo acima merece uns comentários adicionais:\n",
    ">\n",
    ">* Usamos a função [`range()`](https://docs.python.org/3/tutorial/controlflow.html?highlight=range#the-range-function) para cria um objeto da classe [`range`](https://docs.python.org/3/library/stdtypes.html?highlight=range#range) que representa os valores de um intervalo.\n",
    ">* `list()` converte o `range` em um lista real com todos os valores de 0 a 999\n",
    ">* O método `sample()`, finalmente, amostra, aleatoriamente, um subconjunto dos elementos da série.\n",
    "\n",
    "* Aplicar operações aritméticas com todos os elementos da Séries\n",
    "\n",
    "As séries Pandas possuem desempenho excepcional nesse tipo de operação.\n",
    "\n",
    "Listas se comportam de forma diferente, quando a elas é aplicada um operador aritmético."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = pd.Series(list(range(5)))\n",
    "b * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = pd.Series(list(range(5)))\n",
    "b + 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"dfstats\"></a>\n",
    "### 1.G.b DataFrames\n",
    "\n",
    "As funções estatísticas funcionam da mesma maneira para Series e DataFrames e, em ambos os casos, é preciso ficar atento ao tipo do dado antes de fazer os cálculos.\n",
    "\n",
    "O método `info()` descreve o conteúdo do DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como a coluna `a` está marcada como *object* ela não deve ser usada para colher estatísticas sem antes, pelo menos, ser convertida em valores numéricos.\n",
    "\n",
    "No caso desta tabela, os valores da coluna `a` são apenas texto e é melhor remover a coluna antes de calcular as estatísticas. Podemos fazer isso com a [notação de colchetes duplos](#coluna):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1[['b','c']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As funções estatísticas de DataFrames retornam os valores da estatística para cada coluna, como um objeto da classe `pandas.Series`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1[['b','c']].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"limpando\"></a>\n",
    "## 1.H Limpando dados\n",
    "\n",
    "__Valores não definidos__\n",
    "\n",
    "Com frequência, dados são derivados de amostras incompletas, onde valores estão faltando.\n",
    "\n",
    "Dependendo das circunstância podemos:\n",
    "\n",
    "1. Filtrar amostras com valores não-definidos\n",
    "\n",
    "Para simular um valor não definido, vamos usar a biblioteca NumPy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "t1 = pd.read_csv(\"t1.tsv\", sep=\"\\t\")\n",
    "t1['d'] = pd.Series(['a',np.nan,'b'])\n",
    "t1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e podemos localizar a linha com valor não definido (`NaN`) usando:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1[t1.d.isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por fim, podemos excluir essa linha usando o operado `~` (til), que no Pandas equivale a `not`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1[~t1.d.isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Atribuir-lhes um valor padrão\n",
    "\n",
    "Alternativamente, podemos mudar os valores nulos para outro valor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1['d'] = t1.d.fillna(\"n\")\n",
    "t1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Valores duplicados__\n",
    "\n",
    "Se, por alguma razão, os dados coletados possuem linhas duplicadas e essas múltiplas cópias não possuem siginificado real, é fácil removê-las usando `drop_duplicates`.\n",
    "\n",
    "Vamos primeiro gerar linhas duplicadas em nosso DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = pd.read_csv(\"t1.tsv\", sep=\"\\t\")\n",
    "t1 = t1.append(t1)\n",
    "t1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e remover as duplicações:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"merge\"></a>\n",
    "## 1.I Cruzando dados de tabelas diferentes\n",
    "\n",
    "Vamos explorar uma das grandes vantagens de se trabalhar com Pandas: a capacidade de cruzar informações provenientes de arquivos diferentes.\n",
    "\n",
    "Em Pandas, esse tipo de operação é eficiente mesmo quando lidamos com grandes volumes de dados.\n",
    "\n",
    "Primeiro carregamos e inspecionamos nossas duas tabelas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = pd.read_csv(\"t1.tsv\", sep=\"\\t\")\n",
    "t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t2 = pd.read_csv(\"t2.tsv\", sep=\"\\t\")\n",
    "t2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imagine que a tabela `t1` contém os resultados do experimento 1 e a tabela `t2` contém os resultados de experimento 2.\n",
    "\n",
    "* __Pergunta__ 1:\n",
    "Quais amostras (coluna `a`) foram usadas tanto no experimento 1 como no 2?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1.merge(t2, on=\"a\", how=\"inner\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A função `merge` analisa os valores na coluna `a` em todas as linhas das duas tabelas (parâmetro `on=\"a\"`).\n",
    "\n",
    "O parâmetro `how=\"inner\"` significa que apenas linhas com da coluna `a` presentes __nas duas tabelas__ serão mantidas.\n",
    "\n",
    "A ordem das linhas no DataFrame resultante, neste caso, reproduz a ordem na tabela da esquerda (`t1`).\n",
    "\n",
    ">__Nota__:\n",
    ">\n",
    ">Na tabela `t2`, o valor `r1` aparece na coluna `a` __duas vezes__.\n",
    ">\n",
    ">Como em `t1` o mesmo valor aparece uma única vez, os valores nas colunas `b` e `c` são repetidos para mostrar a relação com as duas linhas contendo `r1` na tabela `t2`.\n",
    ">\n",
    ">Isso sempre acontece e o usuário precisa tomar cuidado para __não multiplicar o número de linhas indevidamente__ ou sem controle. Erros acontecem quando repetições não esperadas estão presentes em uma ou mais tabelas.\n",
    ">\n",
    ">Uma forma de controlar para o aparecimento de repetições indesejadas é monitorar constantemente, no DataFrame resultante, o número de elementos nas colunas usadas no `merge()` (parâmetro `on=`) e ver se correspondem ao esperado (veja o próxim exemplo)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* __Pergunta 2:__ Quais amostras foram usadas no experimento 1 e não no 2?\n",
    "\n",
    "Podemos responder essa pergunta usando `merge` e `isna()` e o parâmetro `how=\"left\"`, que implica que todas as linhas da tabela \"da esquerda\" (`t1`) devem ser incluídas no resultado, incluindo as linhas sem correspondente em `t2`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = pd.read_csv(\"t1.tsv\", sep=\"\\t\")\n",
    "t2 = pd.read_csv(\"t2.tsv\", sep=\"\\t\")\n",
    "m = t1.merge(t2, on=\"a\", how=\"left\")\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O `merge()` acima __exige__ que todas as linha de `t1` sejam mantidas.\n",
    "\n",
    "As linhas de `t2` com valores na coluna `a` que não são encontrados em `t1` (`r4`), porém, são descartadas.\n",
    "\n",
    "Aplicando o método `isna()` como filtro para as linhas de `m`, poderemos ver a resposta a nossa pergunta: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m[m.d.isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "que demonstra que apenas a amostra `r2` não foi usada no experimento 2.\n",
    "\n",
    ">__Advertência__: cruzar dados de tabelas pode ser muito complexo e mesmo um `merge()` aparentemente simples pode conter erros.\n",
    "\n",
    "__Como checar se deu tudo certo?__\n",
    "\n",
    "A tabela `t2`, nesse exemplo, tem o valor `r1` repetido na coluna `a`, o resultado do merge vai duplicar, nas colunas `b` e `c`, os valores correspondentes na linha de `r1`.\n",
    "\n",
    "Isso significa que o número de linhas da tabela resultante (`m`) será maior que o número de linhas de `t1` e __não poderemos usar o número de linhas de das duas tabelas__:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(m) == len(t1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "para verificar se apenas as linhas com valores na coluna `a` presentes em `t1` estão na tabela `m`.\n",
    "\n",
    "Esse monitoramento, porém, pode ser feito comparando as listas de elementos na coluna `a`, se ordenarmos esses elementos (`sort_values()`) e removermos suas repetições (`unique()`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.a.sort_values().unique() == t1.a.sort_values().unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Acima já podemos ver que todos os três componentes das duas listas são exatamente iguais pois todos os elementos do [`array()`](https://numpy.org/doc/stable/reference/generated/numpy.array.html) resultante são `True`.\n",
    "\n",
    "Se estivermos lidando com tabelas muito grandes, a funcão `all()` retorná verdadeiro se __todos__ os elementos de uma lista, `array()` ou série forem verdadeiros:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = m.a.sort_values().unique() == t1.a.sort_values().unique()\n",
    "all(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "provando que todas as linhas de `t1` estão representadas em `m`.\n",
    "\n",
    "* __Pergunta 3:__ Quais amostras __não__ foram usadas no experimento 1 mas foram usadas no 2?\n",
    "\n",
    "Da mesma forma que no exemplo anterior, podemos responder essa pergunta usando `merge` e `isna()` mas o parâmetro `how` tem que ser mudado para `how=\"right\"`, que implica que todas as linhas da tabela \"da direita\" (`t2`) devem ser incluídas no resultado, mesmo as sem correspondente em `t1`.\n",
    "\n",
    "Nesse caso porém, precisamos procurar valores não definidos em colunas da tabela `t1`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = pd.read_csv(\"t1.tsv\", sep=\"\\t\")\n",
    "t2 = pd.read_csv(\"t2.tsv\", sep=\"\\t\")\n",
    "m = t1.merge(t2, on=\"a\", how=\"right\")\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* __Pergunta 4:__ Como fazer para ter todo os dados todos na mesma tabela?\n",
    "\n",
    "Usando `merge` podemos ter tudo em um tabela mas, como advertido acima, é preciso ficar atento para a possibilidade de duplicação de valores.\n",
    "\n",
    "Duplicações esperadas ajudam na análise mas se o pesquisador for pego de surpresa os resultados podem não ser os ideais.\n",
    "\n",
    "O parâmetro `how=\"outer\"` garante que todas as linhas das duas tabelas serão mantidas.\n",
    "\n",
    ">Como antes, as linhas de valores sem correspondência recebem valores não-definidos (NaN) nas colunas da outra tabela\n",
    ">\n",
    ">Números inteiros em colunas com valores que não são número inteiros são sempre convertidos em números reais (`np.float`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = pd.read_csv(\"t1.tsv\", sep=\"\\t\")\n",
    "t2 = pd.read_csv(\"t2.tsv\", sep=\"\\t\")\n",
    "m = t1.merge(t2, on=\"a\", how=\"outer\")\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"agrupando\"></a>\n",
    "## 1.J Agrupando linhas\n",
    "\n",
    "Em muitas ocasiões, valore em múltiplas linhas são relacionados e podemos usar as colunas que descrevem as relações entre diferentes linhas para reduzir a informação de várias linhas.\n",
    "\n",
    "Essa operação, chamada __agrupamento__, é feita usando-se o método [`groupby`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.groupby.html) e normalmente seguida do cálculo de um resultado, por grupo, para os valores de uma ou mais colunas.\n",
    "\n",
    "Podemos, por exemplo colapsar as linhas de `r1` em `t2`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t2 = pd.read_csv(\"t2.tsv\", sep=\"\\t\")\n",
    "t2.groupby('a').agg({'d':'mean'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">__Notas__:\n",
    ">\n",
    ">1. O método `agg()` recebe um para dicionário descrevendo o que fazer em cada coluna a ser processada.\n",
    ">\n",
    ">2. O DataFrame retornado pelo método `agg()` está indexado pelos valores originalmente armazendos na coluna `a`.\n",
    ">\n",
    "> Para restaurar o índice como coluna, é preciso invocar o método `reset_index()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t2.groupby('a').agg({'d':'mean','e':'mean'}).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Qualquer função suportada pelo Pandas ou  definidas pelo usuário pode ser invocada para calcular o resultado do agrupamento.\n",
    "\n",
    "Como visto no exemplo acima, qualquer número de colunas pode ser solicitado ao agregador e também é possível solicitar mais de uma valor agregado por coluna:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t2.groupby('a').agg({'d':['mean','median'],'e':['mean','max','min']}).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"visualizacao\"></a>\n",
    "### 1.K Visualização gráfica\n",
    "\n",
    "O Jupyter e o Pandas colaboram muito bem com várias bibliotecas gráficas, incluindo [Matplotlib](https://matplotlib.org/), [Seaborn](https://seaborn.pydata.org/) e outras.\n",
    "\n",
    "No Jupyter, o comando `%matplotlib` prepara a saída dos comandos para formatar os gráficos do Pandas e matplotlib automaticamente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "t2 = pd.read_csv(\"t2.tsv\", sep=\"\\t\")\n",
    "t2.plot.scatter(x='d', y='e', title=\"Scatterplot: d x e\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"exemplo1\"></a>\n",
    "## 2. Exemplos com dados biológicos\n",
    "\n",
    "<a id=\"proteina\"></a>\n",
    "### Qual a proteína?\n",
    "\n",
    "Na aula de similaridade, o programa TBLASTN foi usado para procurar genes semelhantes a proteínas de resistência no genoma *Klebsiella pneumoniae* KPNIH39. No final deste exercício, perguntamos:\n",
    "\n",
    "* __Qual proteína alinha contra mais contigs do genoma de KPNIH39?__\n",
    "\n",
    "Para responder essa pergunta usando Pandas, vamos\n",
    "\n",
    "1. Carregar o arquivo com a saída da análise de TBLASTN (`kpneu.tblastn.tsv`)\n",
    "\n",
    "Os nomes das colunas nessa cópia da tabela são os mesmos listados na documentação do TBLASTN (ver `tblastn -help`). As únicas duas diferenças dos nomes das colunas com a documentação do TBLASTN são as trocas de:\n",
    "\n",
    "* `qaccver` (identificador da *query*) por `protein` e\n",
    "* `saccver` (identificador do *subject*) por `contig`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb = pd.read_csv(\"kpneu.tblastn.tsv\", sep=\"\\t\")\n",
    "tb.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Agrupar as linhas correspondentes a cada proteína e contar o número de contigs por proteína."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = tb.groupby('protein').agg({'contig':'nunique'})\n",
    "p = p.sort_values(['contig'], ascending=False)\n",
    "p.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No resultado acima usamos a função `nunique` para contar o número de contigs por proteína. Essa função difere da função `count` pois evita que o mesmo contig seja contado duas vezes.\n",
    "\n",
    "O resultado acima já responde à pergunta proposta: ANK22461.1.\n",
    "\n",
    "No entanto, poderíamos filtrar especificamente a linha com o valor que nos interessa usando:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = tb.groupby('protein').agg({'contig':'nunique'})\n",
    "p[p.contig == p.contig.max()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* __Qual contig alinha com o maior número de proteínas e quantas são?__\n",
    "\n",
    "A recíproca da pergunta anterior pode ser facilmente respondida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = tb.groupby('contig').agg({'protein':'nunique'})\n",
    "c[c.protein == c.protein.max()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"exemplo_cruzando\"></a>\n",
    "### 2.B Reunindo dados de várias tabelas\n",
    "\n",
    "A tabela do TBLASTN contém apenas informações sobre o alinhamento das proteínas de resistência contra o genoma alvo. Para entender os resultaos precisamos reunir informações que estão dispersas em várias tabelas.\n",
    "\n",
    "Vamos começar carregando a tabela que descreve os genes de resistência."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = pd.read_csv(\"genes.txt\", sep=\"\\t\", names=['protein','function'])\n",
    "g.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = tb.merge(g, on=\"protein\", how=\"left\")\n",
    "f.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com o DataFrame acima, fica mais fácil inspecionar os contigs para ver se existe algum cluster de genes de resistência: as colunas `sstart` e `ssend` são as coordenadas da região alinhada no contig.\n",
    "\n",
    "Basta por as linhas em ordem pela posição no contig:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = f.sort_values(['contig','sstart','send'])\n",
    "f.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E imediatamente podemos ver que as primeiras oito linhas já mostram o que parece ser um *locus* contendo vários genes de resistência a arsênico, um do lado do outro, no contig 215.\n",
    "\n",
    "Se examinarmos as colunas `sstart` e `send`, vamos notar alguns problemas:\n",
    "\n",
    "* Alguns desses genes devem ser homólogos, pois alinham contra a mesma proteína, apesar de estarem localizados posições distantes, como as linhas linhas 93 e 94.\n",
    "* Algumas proteínas, em princípio diferentes, alinham contra a mesma região (linhas 102 e 93), embora com diferenças claras nas qualidade dos alinhamentos (coluna `evalue`).\n",
    "\n",
    ">__Exercício__: Encontre todos os contigs que alinham, __pelo menos uma vez__, contra cinco ou mais proteínas de resistência."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"exemplo_grandes\"></a>\n",
    "### 2.C Tabelas grandes\n",
    "\n",
    "Nossa análise até agora ficou restrita a um único genoma mas há centenas de milhares de genomas de *Klebsiella pneumoniae* no [NCBI](https://www.ncbi.nlm.nih.gov/genome).\n",
    "\n",
    "* __Quais as cinco proteínas de resistência, da nossa lista, com mais cópias idênticas nos genomas do NCBI?__\n",
    "\n",
    "O NCBI disponibiliza listas de proteínas idênticas em seu *site* [Identical Protein Groups](https://www.ncbi.nlm.nih.gov/ipg/).\n",
    "\n",
    "Usando os identificadores das proteínas de resistência de KPNIH39, [baixamos](/edit/source1.sh) a lista correspondente do NCBI/IPG e as armazenamos no arquivo `ipg.tsv`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = pd.read_csv(\"genes.txt\", sep=\"\\t\", names=['protein','function'])\n",
    "ipg = pd.read_csv(\"ipg.tsv\", sep=\"\\t\")\n",
    "len(ipg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipg.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A coluna `Assembly` lista os identificadores dos genomas presentes no NCBI (um *accession* para cada genoma) e a coluna `Protein` contém os *accession numbers* das proteinas, incluindo os identificadores da tabela `genes.txt`.\n",
    "\n",
    "O problema, porém, é que a coluna `Id` identifica os blocos de linhas correspondentes a proteínas idênticas e não sabemos a qual bloco cada proteína de KPNIH39 pertence.\n",
    "\n",
    "Um observador atento vai notar que a coluna Strain identifica as proteínas de KPNIH39 mas vamos usar um procedimento diferente para ilustrar a filtragem de linhas com `isin()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = ipg[ipg.Protein.isin(g.protein)][['Id','Protein']]\n",
    "i.reset_index(inplace=True, drop=True)\n",
    "sum(i.Protein != g.protein)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">O teste na terceira linha verifica se a lista de proteínas em `i` é a mesma que carregamos em `g`.\n",
    ">\n",
    ">O `reset_index()` é necessário pois o operador `!=` (diferente) só vai comparar os elementos de duas `pandas.Series` se eles tiverem recebido os mesmos nomes.\n",
    ">\n",
    ">`sum()` faz a soma dos elementos da série gerada pelo `!=`: valores verdadeiros (`True`) são convertidos em 1 durante a soma e o resultado será maior que zero se pelo menos um dos elementos nas duas listas for diferente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A tabela `i` já informa qual o `Id` das proteínas de KPNIH39 e podemos propagar essa informação para todas as linhas de cada bloco antes de contar o número de genomas por proteína de KPNIH39."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i.rename({'Protein':'KPNIH39'}, axis=1, inplace=True)\n",
    "z = ipg.merge(i, on=\"Id\", how=\"left\")\n",
    "z.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente, calculamos o número de genomas por proteína de KPNIH39 usando [`groupby`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.groupby.html):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = z.groupby('KPNIH39').agg({'Assembly':'nunique'})\n",
    "z.sort_values('Assembly', ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e o resultado mostra o número de genomas onde são encontradas genes para as cinco proteínas, da tabela `genes.txt`, mais amplamente distribuídas nos genomas do NCBI."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
